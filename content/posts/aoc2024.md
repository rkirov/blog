---
title: "Aoc2024"
date: 2024-12-25T21:40:07-08:00
tags: ['aoc']
draft: false
---

# Advent of Code 2024 Retro

Advent of Code [AoC](https://adventofcode.com/) is an annual programming
competition that releases daily coding puzzles throughout December. For the past
four years, I've tackled these challenges from the West Coast, where the 9 PM
PST release time perfectly suits my schedule. While I compete for points on the
global leaderboard (with modest success), the real joy comes from the community
around it. Through Stripe's solution-sharing Slack group, and the active
[r/adventofcode](https://www.reddit.com/r/adventofcode/) community, discussing
creative approaches to challenging problems adds an new dimension to my favorite
pastime - solving puzzles.

This is a retrospective of the most recent (10th year anniversary) 2024
installment of the competition.

## Stats

- total time spent - 17 hours 42 min
- fastest day - day 1 - 0:03:23
- slowest day - day 21 - 3:00:42
- best global rank - 112 (day 20 part 1)
- worst global rank - 3909 (day 3 part 1)
- average global rank - 1014. For comparison '23 - 1062, '22 - 1523, '21 - 1208.

I didn't make the global leaderboard, compared to last year where I
scored global points 3 times, but my rank average improved slightly, so I am
calling it a success.

## Problems

- _hardest problem_ - `Day 21: Keypad Conundrum` - Took me whole 3 hours.
  Something about the recursive nature of the keypads kept throwing me off.
- _most fun problem_ - `Day 24: Crossed Wires` - I haven't taken an EE class
  before, so it was fun to learn about full adders on the fly.
- _most annoying problem_ - `Day 13: Claw Contraption` - I was nerd snipped into
  solving linear Diophantine equations, which do have a nice closed form
  solution, for close to an hour before realizing that one can just solve over
  the reals and check whether the solution is an integer or not.

## Thoughts

This year's competition felt easier than previous years, though this might
simply reflect my growing familiarity with AoC's distinctive style. I've noticed
several patterns that differentiate AoC puzzles from others:

1. Input analysis is crucial. Unlike many programming competitions, AoC provides
   the actual input upfront, encouraging solvers to look for specific patterns
   rather than developing completely general solutions.
1. The toolset is intentionally constrained. While path-finding algorithms and
   basic mathematics are common requirements, reaching for complex algorithms
   usually indicates you overcomplicated the solution.
1. Careful reading matters. There are often some extra conditions in the problem
   statement, so when stuck it is generally a good idea to reread the problem.

I had fewer misreads and basic typos than previous years, but most of my time
was lost overcomplicating the non-trivial days solutions. For example, for
`Keypad Conundrum` I had an initial solution with full enumeration of 16
expansion strategies ('how to go from A to v', etc) and hashmap counting each
transition. The day after I learned that the problem can be solved much more
cleanly with dynamic programming, so I simplified the solution down to [this
DP](https://gist.github.com/rkirov/7dddd9a22e710bbcfb7a950fd804c6af), nearly 5x
shorter than my original code.

## The AI question

A lot of the conversation this year revolved around the use of AI for solving
problems. While the authors of the contest discourage direct AI usage
[here](https://adventofcode.com/2024/about), they also admit that they can't
really stop anyone from doing so. Since it's release, I have been using Github
copilot for all coding including AoC. This would undoubtedly be perceived by
some as cheating. In my defense, many people use AOC as exercise to learn a new
programming language, and I am using it as an exercise to write code with AI
autocompletions, which I do believe will be the future of all programming. I
wouldn't write a doc without a spellchecker, and I don't see myself ever again
coding without AI autocompletion.

That said I resisted pasting any of the problem statement or input into Claude,
but don't feel like I have a much higher ground over people who did. It is a
wide and messy spectrum of `x%` human with `100-x%` AI assisted, and everyone is
picking a spot that works for them. Is 100% human even possible - can using
pre-made specialized AOC libraries or compilers finding errors also seen as
assistance? The fact that we reached a point what `100%` AI is possible is wild,
but it just one more spot on the AI spectrum and unless AOC want to define AI
weight classes (like in sports) might be best to just take global ranking less
seriously. Ultimately, solving the puzzle and reading all other solutions is the
main part of the fun, and I view the global timing as just enough motivation to
do the puzzles at a fixed time and with some urgency.

Speaking of Copilot assisted problem solving, it definitely has been somewhat of
a learning curve on how to best collaborate with it on problem solving. I have
gotten better at instinctively knowing where to just trust Copilot and where to
double-check more. For example, a common mistake that copilot does is write
`grid[y][x]` when I name my index variables `x` and `y`, that can often messes
 up my handwritten accesses that I write as `grid[x][y]`.
 
With AOC problems often are of the shape of classic problem with a twist, and AI
shines an just spitting out the classic solution inline, so I can edit in the
twist. The classic software engineering solution would instead have me rely
indirectly on a privates-protected external library per best its blessed
extension interfaces. Copilot is making it so easy to generate inline that one
starts to doubt the usefulness of import.

## A global phenomenon

Final thought, is that I really enjoyed the fact that AOC has become somewhat of
a big phenomenon. Day 1 was completed by quarter million coders! As a puzzle
connoisseur this feels like the time of the year where I can share my hobby with
the most other people. There is something magical about so many brains focusing
on the same problem for a few hours in the same day. I read the memes and
solutions on [r/adventofcode](https://www.reddit.com/r/adventofcode/) and try to
contribute with the occasional `upping the ante (day 3)`
[post](https://www.reddit.com/r/adventofcode/comments/1hel4lt/2024_day_13_part_3/).

## Future

I do plan to keep doing AOC annually as long as the timing commitments allow me,
but I do wonder if it can continue to evolve in the next 10 years without
becoming captured by the majority of the audience and become repetitive. There
is already a tension between users that want more straight forward coding
challenges and ones that prefer problems that push them to learn new algorithms
or math concepts. Clearly, I am in the second camp, but I can relate to the
frustration of having to learn a new concept on the fly, while competing to time
with someone what just knows it already. AOC is starting to repeat the same
handful types of problems - a 2d path finding problem with a twist, a classic
graph algorithm, a memoized DP, or find the period in a repeating pattern, etc.
Meanwhile, The world of CS and math knowledge is vast and I would love to see
more areas appear in gamified in AOC.

To Eric, AoC's creator (in case he ends up reading this) - Thank you for the
first 10 years of AOC! I hope you continue to push the boundaries with what
might be the biggest CS puzzle community and introduce us to new corners of
computational thinking. We can handle the challenge.